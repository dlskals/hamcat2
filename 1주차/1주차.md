-목표 사이트-

light.gg(게임 데스티니2의 무기 정보를 알려주는 사이트)에서 시즌별 경이 무기의 수와 각 무기의 상세정보 링크를 수집하기

-공부한 crawling 기법들-

lms에 올라와 있는 3개의 사이트를 똑같이 따라해보며 기본적으로 html에서 필요한 정보(얼마나 세분화해서 정보를 가져와야 하는지, 태그와 클래스를 찾는 법, 코드에 활용할 때 어떤식으로 입력해야 하는지,)를 끌고오는 방법 등을 익힘. Beautifulsoup을 사용해 crawling을 하는 방법에 대해 공부함. beautifulsoup과 selenium을 정적, 동적사이트에 잘 활용해야 한다는 것을 깨달음. pandas dataframe을 통해 끌어온 정보를 시각화하는 것을 배움.


-목표 사이트를 접근하기 위해서 수정한 코드 설명-

처음엔 정적사이트와 동적사이트를 차이를 제대로 이해하지 못해서 beaurifulsoup을 써야할지 selenium을 써야할지부터 고민함. lms에 나와있는 https://domdom.tistory.com/633 사이트의 형식을 그대로 사용하려고 시도함.
 
``` python
for items in newitems:
    
    its = items.findAll("div")
    
    for div in its:
        #순서
        items_ranking = div.select_one(".item-check").text
        #링크와 이름
        items_title = div.select_one(".text-exotic ")
        items_name = items_title.text
        items_link = items_title.get("href")
        #  썸네일
        try: items_img = div.select_one("img").get("src")
        except: items_img = None
        print("순서: ", items_ranking)
        print("무기 이름: ", items_name)
        print("링크: ", items_link)
        print("썸네일: ", itmes_img)
        
        break
    break

```

이런식으로 완전히 따라하다보니 try: items_img = div.select_one("img").get("src")처럼 원래 목표했던 것에 필요없는 코드들이 생김. 또한 이떄까지도 태그와 클래스를 끌고올 떄 html에서 어떤 걸 봐야하는 지 잘 몰라 필요없는 태그나 클래스를 가져옴. 태그와 클래스를 찾는 법에 대해 검색해봤지만 html의 형식이 조금 달라지면 다시 헷갈려함. 결국 친구들에게 도움을 받아 코드를 완전히 고침. 

``` python
for i in range(22):
    count_url = f"https://www.light.gg/db/category/-1?page=1&f=5%28{i+1}%29%2C2"
    request = requests.get(count_url, headers = headers)
    page = BeautifulSoup(request.text, 'lxml')
    exotic_count = page.find('div',attrs={'class':'pagination'}).text
    p1 = exotic_count.find("-")
    p2 = exotic_count.find("of")
    page_count = math.ceil(int(exotic_count[p1+2:p2-1]) / 50)
```

사이트의 정보를 끌고올 떄 단순히 사이트의 링크와 무기의 정보가 있는 태그와 클래스만 끌고 왔다면 위의 고친 코드에선 처음부터 시즌별로 나눈 링크를 끌고와 직접 들어가 무기를 보여주는 화면에서 무기의 개수를 세어 for문으로 페이지수를 셈. 경이 무기를 exotic_list에 딕셔너리 형태로 저장하고 겹치는 무기를 제외하는 코드를 만듦.

``` python
 print(f"시즌 {i+1}, 무기 수 {exotic_count[p1+2:p2-1]}, 페이지 수 {page_count}")
    for c in range(page_count):
        url = f"https://www.light.gg/db/category/-1?page={c+1}&f=5%28{i+1}%29%2C2"
        res = requests.get(url, headers = headers)
        soup = BeautifulSoup(res.text, 'lxml')
        items = soup.findAll('div',attrs={'class':'item-row item-row-6'})
        for w in items:
            name = w.find('a',attrs={'class':'text-exotic'}).text
            l = w.find('a',attrs={'class':'text-exotic'}).get("href")
            if name in exotic_list:
                continue
            else :
                exotic_list[name] = f'https://www.light.gg{l}\n'
```

그 후 exotic_list1을 dict()를 사용해 딕셔너리로 만들고 pandas dataframe인 exotic_list_df를 만듦.

``` python
import pandas as pd

exotic_list1 = [dict(exotic_list)]
exotic_list_df = pd.DataFrame(exotic_list1, index = ['cat_egory'])
exotic_list_df.to_csv('exo.csv',index=False,encoding='utf-8-sig')
```
